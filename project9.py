from flask import Flask, Response, render_template_string
import sys
import torch
import cv2
import numpy as np
from picamera2 import Picamera2
from time import sleep
import paho.mqtt.client as mqtt
import threading
import RPi.GPIO as GPIO
from gpiozero import DistanceSensor, Servo
from time import time
import pytesseract
import re
from datetime import datetime

# YOLOv5 setup
sys.path.append('./yolov5')
from models.common import DetectMultiBackend
from utils.general import non_max_suppression, scale_boxes
from utils.torch_utils import select_device

# Flask app initialization
app = Flask(__name__)

# GPIO setup for ultrasonic sensor and servo motor
TRIG_PIN = 17
ECHO_PIN = 27
SERVO_PIN = 18

# Initialize GPIO components
ultrasonic_sensor = DistanceSensor(echo=ECHO_PIN, trigger=TRIG_PIN)
servo_motor = Servo(SERVO_PIN)

# MQTT setup
MQTT_BROKER = 'localhost'
MQTT_PORT = 1883
TOPIC_LICENSE = 'parking/license'
TOPIC_STATUS = 'parking/status'
TOPIC_SENSOR = 'parking/sensor'
TOPIC_SERVO = 'parking/servo'
TOPIC_OCR = 'parking/ocr'  # New topic for OCR results

mqtt_client = mqtt.Client()

def on_mqtt_connect(client, userdata, flags, rc):
    if rc == 0:
        print("MQTT connected successfully!")
    else:
        print(f"MQTT connection failed with code {rc}")

mqtt_client.on_connect = on_mqtt_connect

try:
    mqtt_client.connect(MQTT_BROKER, MQTT_PORT, 60)
    mqtt_client.loop_start()
except:
    print("MQTT connection failed, continuing without MQTT")

# YOLOv5 model initialization
device = select_device('0' if torch.cuda.is_available() else 'cpu')
model = DetectMultiBackend('runs/train/parking_custom/weights/best.pt', device=device)
stride, names = model.stride, model.names

# Picamera2 initialization
picam2 = Picamera2()
picam2.preview_configuration.main.size = (640, 480)
picam2.preview_configuration.main.format = "RGB888"
picam2.configure("preview")
picam2.start()
sleep(2)

# Global variables
latest_detections = []
detection_lock = threading.Lock()
current_distance = 0
servo_position = 0
parking_status = "empty"
latest_ocr_result = ""

# OCR Configuration
# Tesseract ì„¤ì •: í•œêµ­ì–´ ë²ˆí˜¸íŒì— ìµœì í™”
pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'  # ë¼ì¦ˆë² ë¦¬íŒŒì´ ê²½ë¡œ

def preprocess_license_plate(image):
    """ë²ˆí˜¸íŒ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜"""
    # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    
    # ì ì‘ì  ì„ê³„ê°’ì„ ì‚¬ìš©í•œ ì´ì§„í™”
    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                   cv2.THRESH_BINARY, 11, 2)
    
    # ëª¨í´ë¡œì§€ ì—°ì‚°ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°
    kernel = np.ones((2, 2), np.uint8)
    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
    
    # ì´ë¯¸ì§€ í¬ê¸° í™•ëŒ€ (OCR ì •í™•ë„ í–¥ìƒ)
    height, width = cleaned.shape
    resized = cv2.resize(cleaned, (width * 3, height * 3), interpolation=cv2.INTER_CUBIC)
    
    return resized

def extract_text_from_license_plate(image):
    """ë²ˆí˜¸íŒì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
    try:
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        processed_img = preprocess_license_plate(image)
        
        # Tesseract ì„¤ì •
        # í•œêµ­ì–´ ë²ˆí˜¸íŒ íŒ¨í„´: ìˆ«ìì™€ í•œê¸€ ì¡°í•©
        custom_config = r'--oem 3 --psm 8 -c tessedit_char_whitelist=0123456789ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜í—ˆí˜¸êµ¬ëˆ„ë‘ë£¨ë¬´ë¶€ìˆ˜ìš°ì£¼ì¿ íˆ¬í‘¸í›„ì˜ì—­í•˜ê±°ë„ˆë”ëŸ¬ë¨¸ë²„ì„œì–´ì €ì²˜ì»¤í„°í¼'
        
        # OCR ì‹¤í–‰
        text = pytesseract.image_to_string(processed_img, lang='kor+eng', config=custom_config)
        
        # ê²°ê³¼ ì •ë¦¬
        text = text.strip().replace(' ', '').replace('\n', '')
        
        # í•œêµ­ ë²ˆí˜¸íŒ íŒ¨í„´ ê²€ì¦ (ì˜ˆ: 12ê°€1234, 123ë‚˜4567)
        korean_pattern = re.compile(r'[\d]{2,3}[ê°€-í£][\d]{4}')
        matches = korean_pattern.findall(text)
        
        if matches:
            return matches[0]
        else:
            # ì¼ë°˜ì ì¸ ë¬¸ì í•„í„°ë§
            filtered_text = re.sub(r'[^0-9ê°€-í£A-Za-z]', '', text)
            return filtered_text if len(filtered_text) >= 4 else ""
            
    except Exception as e:
        print(f"OCR ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return ""

def log_license_plate_detection(license_text, confidence):
    """ë²ˆí˜¸íŒ ê°ì§€ ë¡œê·¸ ì¶œë ¥"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    print("=" * 60)
    print(f"ğŸ“… ì‹œê°„: {timestamp}")
    print(f"ğŸš— ë²ˆí˜¸íŒ ê°ì§€!")
    print(f"ğŸ“ ì¶”ì¶œëœ í…ìŠ¤íŠ¸: '{license_text}'")
    print(f"ğŸ¯ ì‹ ë¢°ë„: {confidence:.2f}")
    print(f"ğŸ“Š í…ìŠ¤íŠ¸ ê¸¸ì´: {len(license_text)} ë¬¸ì")
    
    if len(license_text) >= 4:
        print(f"âœ… ìœ íš¨í•œ ë²ˆí˜¸íŒìœ¼ë¡œ íŒë‹¨ë¨")
    else:
        print(f"âš ï¸  ì§§ì€ í…ìŠ¤íŠ¸ - ê²€ì¦ í•„ìš”")
    
    print("=" * 60)

def control_servo_motor(angle):
    """Control servo motor angle (0-180 degrees)"""
    global servo_position
    try:
        # Convert angle to servo value (-1 to 1)
        servo_value = (angle - 90) / 90.0
        servo_motor.value = max(-1, min(1, servo_value))
        servo_position = angle
        
        # Send MQTT message
        mqtt_client.publish(TOPIC_SERVO, f"Servo angle: {angle}")
        print(f"ğŸ”§ ì„œë³´ ëª¨í„°: {angle}ë„ë¡œ ì´ë™")
    except Exception as e:
        print(f"ì„œë³´ ëª¨í„° ì œì–´ ì˜¤ë¥˜: {e}")

def read_ultrasonic_sensor():
    """Read distance from ultrasonic sensor"""
    global current_distance, parking_status
    
    while True:
        try:
            # Read distance in centimeters
            distance_cm = ultrasonic_sensor.distance * 100
            current_distance = distance_cm
            
            # Determine parking status based on distance
            if distance_cm < 20:  # Object within 20cm
                new_status = "occupied"
                if parking_status != new_status:
                    control_servo_motor(90)  # Open gate
                    mqtt_client.publish(TOPIC_STATUS, "vehicle_detected")
                    print(f"ğŸš— ì°¨ëŸ‰ ê°ì§€: {distance_cm:.1f}cm")
            else:
                new_status = "empty"
                if parking_status != new_status:
                    control_servo_motor(0)   # Close gate
                    mqtt_client.publish(TOPIC_STATUS, "vehicle_left")
                    print(f"âœ… ì£¼ì°¨ ê³µê°„ ë¹„ì›€: {distance_cm:.1f}cm")
            
            parking_status = new_status
            
            # Send distance data via MQTT
            mqtt_client.publish(TOPIC_SENSOR, f"Distance: {distance_cm:.2f}cm")
            
            sleep(0.5)  # Read every 0.5 seconds
            
        except Exception as e:
            print(f"ì´ˆìŒíŒŒ ì„¼ì„œ ì˜¤ë¥˜: {e}")
            sleep(1)

def detect_objects(frame):
    """YOLOv5 object detection function with OCR"""
    global latest_ocr_result
    
    img = cv2.resize(frame, (320, 320))
    img_input = img[:, :, ::-1].transpose(2, 0, 1)
    img_input = np.ascontiguousarray(img_input)

    img_tensor = torch.from_numpy(img_input).to(device)
    img_tensor = img_tensor.float() / 255.0
    if img_tensor.ndimension() == 3:
        img_tensor = img_tensor.unsqueeze(0)

    # Inference
    pred = model(img_tensor)
    pred = non_max_suppression(pred, conf_thres=0.25, iou_thres=0.45)[0]
    
    detections = []
    license_plates_detected = []
    
    # Process detections
    for *xyxy, conf, cls in pred:
        label = f'{names[int(cls)]} {conf:.2f}'
        xyxy = list(map(int, xyxy))
        
        # Scale coordinates back to original frame size
        xyxy[0] = int(xyxy[0] * frame.shape[1] / 320)
        xyxy[1] = int(xyxy[1] * frame.shape[0] / 320)
        xyxy[2] = int(xyxy[2] * frame.shape[1] / 320)
        xyxy[3] = int(xyxy[3] * frame.shape[0] / 320)
        
        # OCR processing for license plates
        ocr_text = ""
        if 'license' in names[int(cls)].lower() or 'plate' in names[int(cls)].lower():
            try:
                # Extract license plate region
                x1, y1, x2, y2 = xyxy
                license_region = frame[y1:y2, x1:x2]
                
                if license_region.size > 0:  # ì˜ì—­ì´ ìœ íš¨í•œì§€ í™•ì¸
                    # OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
                    ocr_text = extract_text_from_license_plate(license_region)
                    
                    if ocr_text:
                        latest_ocr_result = ocr_text
                        
                        # í„°ë¯¸ë„ì— ê²°ê³¼ ì¶œë ¥
                        log_license_plate_detection(ocr_text, float(conf))
                        
                        # MQTTë¡œ OCR ê²°ê³¼ ì „ì†¡
                        mqtt_client.publish(TOPIC_OCR, f"License: {ocr_text}, Confidence: {conf:.2f}")
                        
                        license_plates_detected.append(f"{label} | Text: {ocr_text}")
                    else:
                        license_plates_detected.append(f"{label} | OCR: Failed")
                        
            except Exception as e:
                print(f"OCR ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
                license_plates_detected.append(f"{label} | OCR: Error")
        
        detections.append({
            'bbox': xyxy,
            'label': label,
            'class': names[int(cls)],
            'confidence': float(conf),
            'ocr_text': ocr_text
        })
    
    # Send MQTT message if license plate detected
    if license_plates_detected:
        try:
            mqtt_client.publish(TOPIC_STATUS, "license_plate_detected")
            mqtt_client.publish(TOPIC_LICENSE, f"Detected: {', '.join(license_plates_detected)}")
            print(f"ğŸ“¡ MQTT ì „ì†¡: ë²ˆí˜¸íŒ ê°ì§€ - {license_plates_detected}")
            
            # Open gate for 5 seconds when license plate detected
            control_servo_motor(90)
            threading.Timer(5.0, lambda: control_servo_motor(0)).start()
            
        except Exception as e:
            print(f"MQTT ì „ì†¡ ì‹¤íŒ¨: {e}")
    
    return detections

def generate_frames():
    """Generate video frames for Flask streaming"""
    global latest_detections
    
    while True:
        try:
            # Capture frame
            frame = picam2.capture_array()
            
            # Detect objects
            detections = detect_objects(frame)
            
            # Update global detections
            with detection_lock:
                latest_detections = detections
            
            # Draw bounding boxes and OCR results
            for detection in detections:
                bbox = detection['bbox']
                label = detection['label']
                ocr_text = detection.get('ocr_text', '')
                
                # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)
                
                # ë¼ë²¨ í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì¡°ì •
                label_y = bbox[1] - 10
                cv2.putText(frame, label, (bbox[0], label_y), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
                
                # OCR ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì¶”ê°€ë¡œ í‘œì‹œ
                if ocr_text:
                    ocr_y = bbox[1] - 30
                    cv2.putText(frame, f"OCR: {ocr_text}", (bbox[0], ocr_y), 
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2)
            
            # Draw sensor information on frame
            cv2.putText(frame, f"Distance: {current_distance:.1f}cm", (10, 30), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, f"Status: {parking_status}", (10, 60), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, f"Servo: {servo_position}Â°", (10, 90), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # OCR ê²°ê³¼ í‘œì‹œ
            if latest_ocr_result:
                cv2.putText(frame, f"Last OCR: {latest_ocr_result}", (10, 120), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
            
            # Encode frame
            ret, buffer = cv2.imencode('.jpg', frame)
            if not ret:
                continue
                
            frame_bytes = buffer.tobytes()
            yield (b'--frame\r\n'
                    b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                    
        except Exception as e:
            print(f"í”„ë ˆì„ ìƒì„± ì˜¤ë¥˜: {e}")
            break

@app.route('/')
def index():
    """Main page with video feed"""
    html_template = '''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Smart Parking System with OCR</title>
        <style>
            body { font-family: Arial, sans-serif; text-align: center; background-color: #f5f5f5; }
            .container { max-width: 1000px; margin: 0 auto; padding: 20px; background-color: white; border-radius: 10px; }
            .video-container { margin: 20px 0; border: 2px solid #ddd; border-radius: 8px; overflow: hidden; }
            .status-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }
            .status-box { padding: 15px; background-color: #e8f5e8; border-radius: 8px; border-left: 4px solid #4CAF50; }
            .ocr-box { background-color: #e8f0ff; border-left: 4px solid #2196F3; }
            .controls { margin: 20px 0; }
            .btn { padding: 10px 20px; margin: 5px; background-color: #4CAF50; color: white; border: none; border-radius: 5px; cursor: pointer; }
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ğŸ…¿ï¸ ìŠ¤ë§ˆíŠ¸ ì£¼ì°¨ ê´€ë¦¬ ì‹œìŠ¤í…œ with OCR</h1>
            
            <div class="video-container">
                <img src="{{ url_for('video_feed') }}" width="640" height="480" alt="Camera Feed">
            </div>
            
            <div class="status-grid">
                <div class="status-box">
                    <h4>ğŸ“¹ ì¹´ë©”ë¼ ìƒíƒœ</h4>
                    <p>ì‹¤ì‹œê°„ ë²ˆí˜¸íŒ ê°ì§€</p>
                </div>
                <div class="status-box">
                    <h4>ğŸ“ ê±°ë¦¬ ì„¼ì„œ</h4>
                    <p id="distance">ì¸¡ì • ì¤‘...</p>
                </div>
                <div class="status-box">
                    <h4>ğŸšª ê²Œì´íŠ¸ ìƒíƒœ</h4>
                    <p id="servo">ì„œë³´ ëª¨í„° ìœ„ì¹˜</p>
                </div>
                <div class="status-box ocr-box">
                    <h4>ğŸ”¤ OCR ê²°ê³¼</h4>
                    <p id="ocr">ë²ˆí˜¸íŒ í…ìŠ¤íŠ¸ ëŒ€ê¸°</p>
                </div>
                <div class="status-box">
                    <h4>ğŸ“¡ MQTT í†µì‹ </h4>
                    <p>ì‹¤ì‹œê°„ ë°ì´í„° ì „ì†¡</p>
                </div>
            </div>
            
            <div class="controls">
                <h3>ğŸ”§ ìˆ˜ë™ ì œì–´</h3>
                <button class="btn" onclick="controlServo(0)">ê²Œì´íŠ¸ ë‹«ê¸° (0Â°)</button>
                <button class="btn" onclick="controlServo(90)">ê²Œì´íŠ¸ ì—´ê¸° (90Â°)</button>
                <button class="btn" onclick="controlServo(180)">ìµœëŒ€ ì—´ê¸° (180Â°)</button>
            </div>
        </div>
        
        <script>
            function controlServo(angle) {
                fetch('/control_servo/' + angle)
                    .then(response => response.json())
                    .then(data => alert('ì„œë³´ ëª¨í„°: ' + data.message));
            }
            
            // Update status every 2 seconds
            setInterval(function() {
                fetch('/status')
                    .then(response => response.json())
                    .then(data => {
                        document.getElementById('distance').textContent = data.distance + 'cm';
                        document.getElementById('servo').textContent = 'ê°ë„: ' + data.servo_angle + 'Â°';
                        document.getElementById('ocr').textContent = data.ocr_result || 'í…ìŠ¤íŠ¸ ì—†ìŒ';
                    });
            }, 2000);
        </script>
    </body>
    </html>
    '''
    return render_template_string(html_template)

@app.route('/video_feed')
def video_feed():
    """Video streaming route"""
    return Response(generate_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/status')
def status():
    """API endpoint for current system status"""
    with detection_lock:
        return {
            'detections': latest_detections,
            'count': len(latest_detections),
            'distance': f"{current_distance:.1f}",
            'parking_status': parking_status,
            'servo_angle': servo_position,
            'ocr_result': latest_ocr_result
        }

@app.route('/control_servo/<int:angle>')
def manual_servo_control(angle):
    """Manual servo control endpoint"""
    if 0 <= angle <= 180:
        control_servo_motor(angle)
        return {'status': 'success', 'message': f'Servo moved to {angle} degrees'}
    else:
        return {'status': 'error', 'message': 'Angle must be between 0 and 180'}

if __name__ == '__main__':
    try:
        print("ğŸš€ Smart Parking System with OCR ì‹œì‘...")
        print("ğŸ“¹ ì¹´ë©”ë¼ í”¼ë“œ: http://localhost:5000")
        print("ğŸ“Š ì‹œìŠ¤í…œ ìƒíƒœ: http://localhost:5000/status")
        print("ğŸ”¤ OCR ê¸°ëŠ¥ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("=" * 50)
        
        # Start ultrasonic sensor thread
        sensor_thread = threading.Thread(target=read_ultrasonic_sensor, daemon=True)
        sensor_thread.start()
        
        app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸  ì‹œìŠ¤í…œ ì¢…ë£Œ ì¤‘...")
    finally:
        picam2.stop()
        mqtt_client.loop_stop()
        mqtt_client.disconnect()
        GPIO.cleanup()
        print("âœ… ì‹œìŠ¤í…œì´ ì•ˆì „í•˜ê²Œ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")