from flask import Flask, Response, render_template_string
import sys
import torch
import cv2
import numpy as np
from time import sleep
import paho.mqtt.client as mqtt
from paho.mqtt.client import CallbackAPIVersion
import threading
from time import time
import easyocr
import re
import logging
import os
import subprocess
import ssl
from collections import Counter
import json
from datetime import datetime
import RPi.GPIO as GPIO

# ë””ë²„ê¹… ë ˆë²¨ ì„¤ì •
DEBUG_LEVEL = {
    'SYSTEM': True,      # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    'CAMERA': True,      # ì¹´ë©”ë¼ ê´€ë ¨
    'SENSOR': True,      # ì´ˆìŒíŒŒì„¼ì„œ
    'YOLO': True,        # YOLOv5 ê°ì§€
    'OCR': True,         # OCR ì²˜ë¦¬
    'MQTT': True,        # MQTT í†µì‹ 
    'SERVO': True,       # ì„œë³´ëª¨í„°
    'PARKING': True      # ì£¼ì°¨ ê´€ë¦¬
}

def debug_print(category, message):
    """ë””ë²„ê¹… ì¶œë ¥ í•¨ìˆ˜"""
    if DEBUG_LEVEL.get(category, False):
        timestamp = datetime.now().strftime('%H:%M:%S.%f')[:-3]
        print(f"[{timestamp}] [{category}] {message}")

# ì‹œìŠ¤í…œ ì¸ì½”ë”© ì„¤ì •
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')

debug_print('SYSTEM', "System encoding set to UTF-8")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('/tmp/parking_system.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)
debug_print('SYSTEM', "Logging system initialized")

# YOLOv5 setup
sys.path.append('./yolov5')
from models.common import DetectMultiBackend
from utils.general import non_max_suppression
from utils.torch_utils import select_device

debug_print('SYSTEM', "YOLOv5 modules imported")

# Flask app initialization
app = Flask(__name__)
debug_print('SYSTEM', "Flask app initialized")

# HiveMQ Cloud MQTT setup
HIVEMQ_URL = '6930cfddf53544a49b88c300d312a4f7.s1.eu.hivemq.cloud'
HIVEMQ_PORT = 8883
HIVEMQ_USERNAME = 'hsjpi'
HIVEMQ_PASSWORD = 'hseojin0939PI'

# MQTT Topics - ì…ì¶œì°¨ êµ¬ë¶„
TOPIC_ENTRY = 'parking/entry'
TOPIC_EXIT = 'parking/exit'
TOPIC_PAYMENT = 'parking/payment'
TOPIC_OCR = 'parking/ocr'
TOPIC_LICENSE = 'parking/license'
TOPIC_STATUS = 'parking/status'
TOPIC_SENSOR = 'parking/sensor'
TOPIC_SERVO = 'parking/servo'

debug_print('MQTT', f"MQTT broker: {HIVEMQ_URL}:{HIVEMQ_PORT}")

# GPIO í•€ ì„¤ì •
TRIG_PIN = 17
ECHO_PIN = 27
SERVO_PIN = 18
DISTANCE_THRESHOLD = 10.0  # 10cm ê±°ë¦¬ ì„ê³„ê°’

debug_print('SYSTEM', f"GPIO pins - TRIG: {TRIG_PIN}, ECHO: {ECHO_PIN}, SERVO: {SERVO_PIN}")
debug_print('SENSOR', f"Distance threshold: {DISTANCE_THRESHOLD}cm")

# GPIO ì´ˆê¸°í™”
try:
    GPIO.setmode(GPIO.BCM)
    GPIO.setup(TRIG_PIN, GPIO.OUT)
    GPIO.setup(ECHO_PIN, GPIO.IN)
    GPIO.setup(SERVO_PIN, GPIO.OUT)
    debug_print('SYSTEM', "GPIO setup completed successfully")
    
    # ì„œë³´ëª¨í„° PWM ì„¤ì •
    servo_pwm = GPIO.PWM(SERVO_PIN, 50)  # 50Hz
    servo_pwm.start(0)
    debug_print('SERVO', "Servo PWM initialized (50Hz)")
    
except Exception as e:
    debug_print('SYSTEM', f"GPIO setup failed: {e}")

# MQTT Client ìƒì„±
mqtt_client = mqtt.Client(CallbackAPIVersion.VERSION1)
debug_print('MQTT', "MQTT client created with VERSION1")

def safe_mqtt_publish(topic, message):
    try:
        if isinstance(message, str):
            mqtt_client.publish(topic, message.encode('utf-8'))
        else:
            mqtt_client.publish(topic, message)
        
        # í•µì‹¬ ì •ë³´ë§Œ ë¡œê¹…
        if topic in [TOPIC_ENTRY, TOPIC_EXIT, TOPIC_PAYMENT]:
            debug_print('MQTT', f"Published to {topic}: {message}")
            logger.info(f"MQTT: {topic} -> {message}")
    except Exception as e:
        debug_print('MQTT', f"Publish error to {topic}: {e}")

def on_connect(client, userdata, flags, rc):
    if rc == 0:
        debug_print('MQTT', "HiveMQ Cloud connection successful")
        logger.info("HiveMQ Cloud MQTT connected successfully!")
        print("HiveMQ Cloud MQTT connection successful!")
        
        # í† í”½ êµ¬ë…
        client.subscribe(f"{TOPIC_STATUS}/control")
        client.subscribe(f"{TOPIC_SERVO}/control")
        debug_print('MQTT', "Subscribed to control topics")
        print("Subscribed to control topics")
        
    else:
        debug_print('MQTT', f"Connection failed with code: {rc}")
        logger.error(f"HiveMQ Cloud MQTT connection failed with code {rc}")
        print(f"HiveMQ Cloud MQTT connection failed: {rc}")

def on_message(client, userdata, msg):
    try:
        topic = msg.topic
        message = msg.payload.decode('utf-8')
        debug_print('MQTT', f"Received from {topic}: {message}")
        logger.info(f"MQTT received from {topic}: {message}")
        print(f"MQTT received: {topic} -> {message}")
    except Exception as e:
        debug_print('MQTT', f"Message handling error: {e}")
        logger.error(f"MQTT message handling error: {e}")

def on_disconnect(client, userdata, rc):
    debug_print('MQTT', f"HiveMQ Cloud disconnected with code: {rc}")
    logger.warning(f"HiveMQ Cloud MQTT disconnected with code {rc}")
    print(f"HiveMQ Cloud MQTT disconnected: {rc}")

# MQTT í´ë¼ì´ì–¸íŠ¸ ì„¤ì •
mqtt_client.on_connect = on_connect
mqtt_client.on_message = on_message
mqtt_client.on_disconnect = on_disconnect

# HiveMQ Cloud ì¸ì¦ ë° TLS ì„¤ì •
mqtt_client.username_pw_set(HIVEMQ_USERNAME, HIVEMQ_PASSWORD)
mqtt_client.tls_set(
    ca_certs=None, 
    certfile=None, 
    keyfile=None,
    cert_reqs=ssl.CERT_REQUIRED,
    tls_version=ssl.PROTOCOL_TLS,
    ciphers=None
)

try:
    debug_print('MQTT', "Attempting to connect to HiveMQ Cloud...")
    mqtt_client.connect(HIVEMQ_URL, HIVEMQ_PORT, 60)
    mqtt_client.loop_start()
    debug_print('MQTT', "MQTT client loop started")
    logger.info("HiveMQ Cloud MQTT client started")
    print("HiveMQ Cloud MQTT client started")
except Exception as e:
    debug_print('MQTT', f"Connection failed: {e}")
    logger.error(f"HiveMQ Cloud MQTT connection failed: {e}")
    print(f"HiveMQ Cloud MQTT connection failed: {e}")

# YOLOv5 model initialization
debug_print('YOLO', "Starting YOLOv5 model initialization...")
logger.info("YOLOv5 model initialization started...")
print("YOLOv5 model loading...")

device = select_device('0' if torch.cuda.is_available() else 'cpu')
debug_print('YOLO', f"Selected device: {device}")

try:
    debug_print('YOLO', "Trying to load custom parking model...")
    model = DetectMultiBackend('runs/train/parking_custom320/weights/best.pt', device=device)
    debug_print('YOLO', "Custom parking model loaded successfully")
    print("Custom parking model loaded successfully")
except:
    try:
        debug_print('YOLO', "Custom model failed, trying default YOLOv5s...")
        model = DetectMultiBackend('yolov5s.pt', device=device)
        debug_print('YOLO', "Default YOLOv5s model loaded")
        print("Using default YOLOv5s model")
    except:
        debug_print('YOLO', "All model loading failed")
        print("Failed to load any YOLOv5 model")
        raise

stride, names = model.stride, model.names
debug_print('YOLO', f"Model stride: {stride}")
debug_print('YOLO', f"Detection classes: {names}")
logger.info(f"YOLOv5 model loaded successfully. Classes: {names}")
print(f"YOLOv5 model loaded successfully. Detection classes: {names}")

# EasyOCR ì´ˆê¸°í™”
def initialize_easyocr():
    """EasyOCR ì´ˆê¸°í™” - í•œêµ­ì–´ ìš°ì„ """
    try:
        debug_print('OCR', "Starting EasyOCR initialization...")
        print("EasyOCR initialization started...")
        
        # í•œêµ­ì–´ + ì˜ì–´ ëª¨ë¸ ì‹œë„
        try:
            debug_print('OCR', "Attempting Korean + English model...")
            reader = easyocr.Reader(['ko', 'en'])
            debug_print('OCR', "Korean + English model loaded successfully")
            print("EasyOCR initialized with Korean + English support")
            return reader, True
        except Exception as e:
            debug_print('OCR', f"Korean model failed: {e}")
            print(f"Korean model failed, trying English only: {e}")
            
            # ì˜ì–´ë§Œ ëª¨ë¸ë¡œ í´ë°±
            debug_print('OCR', "Attempting English only model...")
            reader = easyocr.Reader(['en'])
            debug_print('OCR', "English only model loaded successfully")
            print("EasyOCR initialized with English only")
            return reader, False
            
    except Exception as e:
        debug_print('OCR', f"EasyOCR initialization completely failed: {e}")
        print(f"EasyOCR initialization failed: {e}")
        logger.error(f"EasyOCR initialization failed: {e}")
        return None, False

# EasyOCR ì´ˆê¸°í™” ì‹¤í–‰
easyocr_reader, korean_support = initialize_easyocr()

# ì›¹ìº  ì´ˆê¸°í™” (ì‘ë™í•˜ëŠ” ì½”ë“œ ë°©ì‹ ì‚¬ìš©)
try:
    debug_print('CAMERA', "Starting webcam initialization...")
    cap = cv2.VideoCapture(0)
    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
    debug_print('CAMERA', "VideoCapture object created and resolution set")
    
    if cap.isOpened():
        camera_available = True
        debug_print('CAMERA', "Webcam opened successfully")
        logger.info("Webcam initialization successful")
        print("Webcam initialization successful")
        
        # ì‹¤ì œ ì„¤ì •ê°’ í™•ì¸
        actual_width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)
        actual_height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
        debug_print('CAMERA', f"Actual webcam resolution: {actual_width}x{actual_height}")
        print(f"Actual webcam resolution: {actual_width}x{actual_height}")
    else:
        camera_available = False
        debug_print('CAMERA', "Webcam failed to open")
        logger.error("Webcam initialization failed")
        print("Webcam initialization failed")
        
except Exception as e:
    debug_print('CAMERA', f"Webcam initialization failed: {e}")
    logger.error(f"Webcam initialization failed: {e}")
    print(f"Webcam initialization failed: {e}")
    camera_available = False
    cap = None

# Global variables
latest_detections = []
detection_lock = threading.Lock()
latest_ocr_text = ""
ocr_debug_info = ""
parking_data = {}  # ì…ì°¨ ë°ì´í„° ì €ì¥
system_mode = "ENTRY"  # ENTRY ë˜ëŠ” EXIT

# ë”ë¯¸ ë³€ìˆ˜ë“¤ (ì‘ë™í•˜ëŠ” ì½”ë“œì™€ í˜¸í™˜ì„± ìœ ì§€)
current_distance = 0
servo_position = 0
parking_status = "empty"

debug_print('SYSTEM', f"Global variables initialized, system mode: {system_mode}")

# ì—°ì† í”„ë ˆì„ OCR ê²€ì¦ ì‹œìŠ¤í…œ
ocr_buffer = []
confidence_threshold = 0.8

debug_print('OCR', f"OCR buffer system initialized, confidence threshold: {confidence_threshold}")

def get_most_frequent_result(ocr_buffer):
    debug_print('OCR', f"Analyzing OCR buffer with {len(ocr_buffer)} results")
    
    if not ocr_buffer:
        debug_print('OCR', "OCR buffer is empty")
        return None, 0
    
    result_counts = Counter([result for result, conf in ocr_buffer])
    max_count = max(result_counts.values())
    most_frequent = [result for result, count in result_counts.items() if count == max_count]
    
    debug_print('OCR', f"Result counts: {dict(result_counts)}")
    debug_print('OCR', f"Most frequent results: {most_frequent}")
    
    best_result = None
    best_confidence = 0
    
    for result in most_frequent:
        confidences = [conf for res, conf in ocr_buffer if res == result]
        avg_confidence = sum(confidences) / len(confidences)
        
        if avg_confidence > best_confidence:
            best_result = result
            best_confidence = avg_confidence
    
    debug_print('OCR', f"Selected best result: '{best_result}' with confidence: {best_confidence:.2f}")
    return best_result, best_confidence

def validate_ocr_result(new_result, confidence):
    global ocr_buffer
    
    debug_print('OCR', f"Validating OCR result: '{new_result}' (confidence: {confidence:.2f})")
    
    if new_result and len(new_result.strip()) >= 4:
        ocr_buffer.append((new_result, confidence))
        debug_print('OCR', f"Added to buffer. Buffer size: {len(ocr_buffer)}")
        
        if len(ocr_buffer) > 5:
            removed = ocr_buffer.pop(0)
            debug_print('OCR', f"Removed oldest result: '{removed[0]}'")
    
    if len(ocr_buffer) >= 3:
        best_result, best_confidence = get_most_frequent_result(ocr_buffer)
        
        if best_confidence >= confidence_threshold:
            debug_print('OCR', f"âœ… OCR VALIDATED: '{best_result}' (confidence: {best_confidence:.2f})")
            return best_result, best_confidence, True
        else:
            debug_print('OCR', f"â³ OCR PENDING: '{best_result}' (confidence: {best_confidence:.2f}) - Need more data")
            return best_result, best_confidence, False
    else:
        debug_print('OCR', f"ğŸ“Š OCR COLLECTING: {len(ocr_buffer)}/3 samples needed")
        return None, 0, False

def clear_ocr_buffer():
    global ocr_buffer
    ocr_buffer.clear()
    debug_print('OCR', "ğŸ”„ OCR Buffer cleared for new vehicle")

# ì‹¤ì œ í•˜ë“œì›¨ì–´ ì œì–´ í•¨ìˆ˜ë“¤
def measure_distance():
    """ì´ˆìŒíŒŒì„¼ì„œë¡œ ì‹¤ì œ ê±°ë¦¬ ì¸¡ì •"""
    try:
        debug_print('SENSOR', "Starting distance measurement...")
        
        GPIO.output(TRIG_PIN, False)
        sleep(0.05)

        GPIO.output(TRIG_PIN, True)
        sleep(0.00001)
        GPIO.output(TRIG_PIN, False)

        pulse_start = time()
        pulse_end = time()

        while GPIO.input(ECHO_PIN) == 0:
            pulse_start = time()

        while GPIO.input(ECHO_PIN) == 1:
            pulse_end = time()

        pulse_duration = pulse_end - pulse_start
        distance = pulse_duration * 17150  # cm
        distance = round(distance, 2)
        
        debug_print('SENSOR', f"Measured distance: {distance}cm")
        return distance
    except Exception as e:
        debug_print('SENSOR', f"Distance measurement error: {e}")
        return 999  # ì˜¤ë¥˜ ì‹œ í° ê°’ ë°˜í™˜

def set_servo_angle(angle):
    """ì„œë³´ëª¨í„° ì‹¤ì œ ê°ë„ ì œì–´"""
    try:
        debug_print('SERVO', f"Setting servo angle to {angle} degrees")
        duty = angle / 18 + 2
        GPIO.output(SERVO_PIN, True)
        servo_pwm.ChangeDutyCycle(duty)
        sleep(0.5)
        GPIO.output(SERVO_PIN, False)
        servo_pwm.ChangeDutyCycle(0)
        debug_print('SERVO', f"Servo angle set successfully: {angle}Â°")
    except Exception as e:
        debug_print('SERVO', f"Servo control error: {e}")

# ì…ì¶œì°¨ ê´€ë¦¬ í•¨ìˆ˜ë“¤
def handle_entry(plate_number):
    """ì…ì°¨ ì²˜ë¦¬"""
    debug_print('PARKING', f"Processing entry for plate: {plate_number}")
    
    now = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    parking_data[plate_number] = {'entry_time': now}
    
    entry_data = {
        'plate_number': plate_number,
        'entry_time': now,
        'action': 'ENTRY'
    }
    
    safe_mqtt_publish(TOPIC_ENTRY, json.dumps(entry_data))
    debug_print('PARKING', f"ENTRY processed: {plate_number} at {now}")
    print(f"ENTRY: {plate_number} at {now}")
    
    # ê²Œì´íŠ¸ ì—´ê¸°
    set_servo_angle(90)
    threading.Timer(5.0, lambda: set_servo_angle(0)).start()

def handle_exit(plate_number):
    """ì¶œì°¨ ì²˜ë¦¬"""
    debug_print('PARKING', f"Processing exit for plate: {plate_number}")
    
    now = datetime.now()
    
    if plate_number in parking_data:
        entry_time_str = parking_data[plate_number]['entry_time']
        entry_time = datetime.strptime(entry_time_str, '%Y-%m-%d %H:%M:%S')
        duration_seconds = (now - entry_time).total_seconds()
        
        # ìš”ê¸ˆ ê³„ì‚° (ê¸°ë³¸ 1000ì› + 10ë¶„ë‹¹ 500ì›)
        base_fee = 1000
        duration_minutes = duration_seconds / 60
        additional_fee = max(0, (duration_minutes - 30)) * (500 / 10)  # 30ë¶„ í›„ë¶€í„° 10ë¶„ë‹¹ 500ì›
        total_fee = int(base_fee + additional_fee)
        
        exit_data = {
            'plate_number': plate_number,
            'entry_time': entry_time_str,
            'exit_time': now.strftime('%Y-%m-%d %H:%M:%S'),
            'duration_minutes': round(duration_minutes, 1),
            'total_fee': total_fee,
            'action': 'EXIT'
        }
        
        safe_mqtt_publish(TOPIC_EXIT, json.dumps(exit_data))
        safe_mqtt_publish(TOPIC_PAYMENT, f"Payment: {plate_number} - {total_fee} won")
        debug_print('PARKING', f"EXIT processed: {plate_number} - Duration: {duration_minutes:.1f}min - Fee: {total_fee}won")
        print(f"EXIT: {plate_number} - Duration: {duration_minutes:.1f}min - Fee: {total_fee}won")
        
        del parking_data[plate_number]
        
        # ê²Œì´íŠ¸ ì—´ê¸°
        set_servo_angle(90)
        threading.Timer(5.0, lambda: set_servo_angle(0)).start()
        
        return total_fee
    else:
        debug_print('PARKING', f"EXIT ATTEMPT: Unknown plate {plate_number}")
        print(f"EXIT ATTEMPT: Unknown plate {plate_number}")
        return None

def enhanced_preprocessing_for_easyocr(image):
    """EasyOCRì— ìµœì í™”ëœ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
    try:
        debug_print('OCR', "Starting image preprocessing for EasyOCR")
        
        # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        if len(image.shape) == 3:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        else:
            gray = image.copy()
        
        # EasyOCRì— ì í•©í•œ í¬ê¸°ë¡œ ì¡°ì • (224x128 ê¸°ì¤€)
        height, width = gray.shape
        target_width = 224
        target_height = 128
        
        # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ í¬ê¸° ì¡°ì •
        aspect_ratio = width / height
        if aspect_ratio > target_width / target_height:
            new_width = target_width
            new_height = int(target_width / aspect_ratio)
        else:
            new_height = target_height
            new_width = int(target_height * aspect_ratio)
        
        resized = cv2.resize(gray, (new_width, new_height), interpolation=cv2.INTER_CUBIC)
        
        # ëŒ€ë¹„ í–¥ìƒ
        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))
        enhanced = clahe.apply(resized)
        
        # ë…¸ì´ì¦ˆ ì œê±°
        denoised = cv2.medianBlur(enhanced, 3)
        
        debug_print('OCR', f"Preprocessing complete: {gray.shape} -> {denoised.shape}")
        return denoised
        
    except Exception as e:
        debug_print('OCR', f"Preprocessing error: {e}")
        return image

def extract_text_with_easyocr(license_plate_image):
    """EasyOCRì„ ì‚¬ìš©í•œ ë²ˆí˜¸íŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ - ì—°ì† í”„ë ˆì„ ê²€ì¦"""
    global ocr_debug_info
    
    if easyocr_reader is None:
        debug_print('OCR', "EasyOCR reader not available")
        print("EasyOCR not available")
        ocr_debug_info = "EasyOCR not available"
        return None
    
    try:
        debug_print('OCR', "Starting EasyOCR text extraction (Korean Priority + Frame Validation)")
        print("EasyOCR license plate extraction started (Korean Priority)")
        
        # EasyOCRì— ìµœì í™”ëœ ì „ì²˜ë¦¬
        processed = enhanced_preprocessing_for_easyocr(license_plate_image)
        
        # ë””ë²„ê¹…ìš© ì´ë¯¸ì§€ ì €ì¥
        timestamp = int(time())
        cv2.imwrite(f'/tmp/license_original_{timestamp}.jpg', license_plate_image)
        cv2.imwrite(f'/tmp/license_processed_{timestamp}.jpg', processed)
        debug_print('OCR', f"Debug images saved: /tmp/license_*_{timestamp}.jpg")
        
        # EasyOCR ì‹¤í–‰
        debug_print('OCR', "Running EasyOCR readtext...")
        print("Running EasyOCR...")
        results = easyocr_reader.readtext(processed)
        
        debug_print('OCR', f"EasyOCR detected {len(results)} text regions")
        print(f"EasyOCR detected {len(results)} text regions")
        
        # ê²°ê³¼ ì²˜ë¦¬ - í•œêµ­ì–´ ìš°ì„ 
        korean_results = []
        english_results = []
        
        for i, (bbox, text, confidence) in enumerate(results):
            debug_print('OCR', f"Result {i+1}: '{text}' (confidence: {confidence:.2f})")
            print(f"EasyOCR result: '{text}' (confidence: {confidence:.2f})")
            
            if confidence > 0.5:  # ì‹ ë¢°ë„ 50% ì´ìƒ
                text_clean = text.replace(' ', '').replace('\n', '').replace('\t', '')
                
                # í•œêµ­ì–´ íŒ¨í„´ ìš°ì„  í™•ì¸
                korean_patterns = [
                    r'^[0-9]{2,3}[ê°€-í£][0-9]{4}$',  # 12ê°€3456
                    r'^[ê°€-í£]{2}[0-9]{2}[ê°€-í£][0-9]{4}$',  # ì„œìš¸12ê°€3456
                    r'^[0-9]{2}[ê°€-í£][0-9]{4}$'   # 12ê°€3456
                ]
                
                # í•œêµ­ì–´ íŒ¨í„´ ë§¤ì¹­
                for pattern in korean_patterns:
                    if re.match(pattern, text_clean):
                        debug_print('OCR', f"Korean pattern matched: {text_clean}")
                        print(f"Korean pattern matched: {text_clean}")
                        korean_results.append((text_clean, confidence))
                        break
                else:
                    # í•œê¸€ì´ í¬í•¨ëœ ê²½ìš°
                    if re.search(r'[ê°€-í£]', text_clean):
                        debug_print('OCR', f"Korean characters detected: {text_clean}")
                        print(f"Korean characters detected: {text_clean}")
                        korean_results.append((text_clean, confidence))
                    # ì˜ë¬¸+ìˆ«ì ì¡°í•©
                    elif len(text_clean) >= 4 and re.match(r'^[A-Z0-9]+$', text_clean):
                        debug_print('OCR', f"English pattern detected: {text_clean}")
                        print(f"English pattern detected: {text_clean}")
                        english_results.append((text_clean, confidence))
        
        # ê²°ê³¼ ìš°ì„ ìˆœìœ„: í•œêµ­ì–´ > ì˜ì–´
        current_result = None
        current_confidence = 0
        
        if korean_results:
            # ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ í•œêµ­ì–´ ê²°ê³¼ ì„ íƒ
            best_korean = max(korean_results, key=lambda x: x[1])
            current_result = best_korean[0]
            current_confidence = best_korean[1]
            debug_print('OCR', f"Selected Korean result: {current_result} (confidence: {current_confidence:.2f})")
            print(f"Current frame result (Korean): {current_result} (confidence: {current_confidence:.2f})")
            
        elif english_results:
            # ì‹ ë¢°ë„ê°€ ê°€ì¥ ë†’ì€ ì˜ì–´ ê²°ê³¼ ì„ íƒ
            best_english = max(english_results, key=lambda x: x[1])
            current_result = best_english[0]
            current_confidence = best_english[1]
            debug_print('OCR', f"Selected English result: {current_result} (confidence: {current_confidence:.2f})")
            print(f"Current frame result (English): {current_result} (confidence: {current_confidence:.2f})")
        
        # ì—°ì† í”„ë ˆì„ ê²€ì¦ ì ìš©
        if current_result:
            validated_result, validated_confidence, is_approved = validate_ocr_result(current_result, current_confidence)
            
            if is_approved:
                ocr_debug_info = f"Validated Success: {validated_result} ({validated_confidence:.2f})"
                debug_print('OCR', f"âœ… OCR APPROVED: {validated_result}")
                print(f"Final result (Korean): {validated_result} (confidence: {validated_confidence:.2f})")
                return validated_result
            else:
                ocr_debug_info = f"Validation Pending: {validated_result or 'Collecting...'}"
                debug_print('OCR', "â³ OCR validation pending")
                return None  # ì•„ì§ ìŠ¹ì¸ë˜ì§€ ì•ŠìŒ
        
        # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ ì„ íƒ
        all_texts = [(text, conf) for (bbox, text, conf) in results if conf > 0.3]
        if all_texts:
            longest_text = max(all_texts, key=lambda x: len(x[0].strip()))
            if len(longest_text[0].strip()) >= 3:
                fallback_result = longest_text[0].strip().replace(' ', '')
                debug_print('OCR', f"Fallback result: {fallback_result} (confidence: {longest_text[1]:.2f})")
                print(f"Fallback result: {fallback_result} (confidence: {longest_text[1]:.2f})")
                
                # í´ë°± ê²°ê³¼ë„ ì—°ì† í”„ë ˆì„ ê²€ì¦ ì ìš©
                validated_result, validated_confidence, is_approved = validate_ocr_result(fallback_result, longest_text[1])
                
                if is_approved:
                    ocr_debug_info = f"Fallback Validated: {validated_result} ({validated_confidence:.2f})"
                    debug_print('OCR', f"âœ… Fallback OCR APPROVED: {validated_result}")
                    return validated_result
                else:
                    ocr_debug_info = f"Fallback Pending: {validated_result or 'Collecting...'}"
                    debug_print('OCR', "â³ Fallback OCR validation pending")
                    return None
        
        debug_print('OCR', "No valid OCR results found")
        print("EasyOCR: No valid text detected")
        ocr_debug_info = "EasyOCR: No valid text"
        return None
        
    except Exception as e:
        debug_print('OCR', f"EasyOCR extraction error: {e}")
        print(f"EasyOCR error: {e}")
        logger.error(f"EasyOCR error: {e}")
        ocr_debug_info = f"EasyOCR error: {e}"
        return None

def control_servo_motor(angle):
    """ì„œë³´ëª¨í„° ì œì–´ (ë”ë¯¸ + ì‹¤ì œ í†µí•©)"""
    global servo_position
    servo_position = angle
    safe_mqtt_publish(TOPIC_SERVO, f"Servo angle: {angle}")
    
    # ì‹¤ì œ ì„œë³´ëª¨í„° ì œì–´
    set_servo_angle(angle)
    
    debug_print('SERVO', f"Servo motor: {angle} degrees")
    print(f"Servo motor: {angle} degrees")

def read_ultrasonic_sensor():
    """ì‹¤ì œ ì´ˆìŒíŒŒì„¼ì„œ ëª¨ë‹ˆí„°ë§"""
    global current_distance, parking_status
    
    debug_print('SENSOR', "Starting ultrasonic sensor monitoring thread")
    print("Ultrasonic sensor monitoring started")
    
    while True:
        try:
            distance_cm = measure_distance()
            current_distance = distance_cm
            
            # 10cm ì´ë‚´ë¡œ ì ‘ê·¼ ì‹œ YOLOv5 í™œì„±í™” íŠ¸ë¦¬ê±°
            if distance_cm <= DISTANCE_THRESHOLD:
                new_status = "occupied"
                if parking_status != new_status:
                    debug_print('SENSOR', f"ğŸš— Vehicle detected at {distance_cm}cm (threshold: {DISTANCE_THRESHOLD}cm)")
                    print(f"Vehicle detected at {distance_cm}cm - Activating license plate detection")
                    safe_mqtt_publish(TOPIC_STATUS, "vehicle_detected")
            else:
                new_status = "empty"
                if parking_status != new_status:
                    debug_print('SENSOR', f"Vehicle left - distance: {distance_cm}cm")
                    safe_mqtt_publish(TOPIC_STATUS, "vehicle_left")
            
            parking_status = new_status
            safe_mqtt_publish(TOPIC_SENSOR, f"Distance: {distance_cm:.2f}cm")
            sleep(0.5)  # 0.5ì´ˆë§ˆë‹¤ ê±°ë¦¬ ì¸¡ì •
            
        except Exception as e:
            debug_print('SENSOR', f"Ultrasonic sensor error: {e}")
            sleep(1)

def detect_objects(frame):
    """YOLOv5 ê°ì²´ ê°ì§€ + EasyOCR ë²ˆí˜¸íŒ ì¸ì‹ (ì—°ì† í”„ë ˆì„ ê²€ì¦)"""
    global latest_ocr_text
    
    try:
        debug_print('YOLO', "Starting object detection")
        
        # ê±°ë¦¬ í™•ì¸ (10cm ì´ë‚´ì¼ ë•Œë§Œ ì²˜ë¦¬)
        current_distance = measure_distance()
        if current_distance > DISTANCE_THRESHOLD:
            debug_print('YOLO', f"Distance {current_distance}cm > threshold {DISTANCE_THRESHOLD}cm, skipping detection")
            return []
        
        debug_print('YOLO', f"Distance {current_distance}cm <= threshold {DISTANCE_THRESHOLD}cm, proceeding with detection")
        
        img = cv2.resize(frame, (320, 320))
        img_input = img[:, :, ::-1].transpose(2, 0, 1)
        img_input = np.ascontiguousarray(img_input)

        img_tensor = torch.from_numpy(img_input).to(device)
        img_tensor = img_tensor.float() / 255.0
        if img_tensor.ndimension() == 3:
            img_tensor = img_tensor.unsqueeze(0)

        # Inference
        debug_print('YOLO', "Running YOLOv5 inference...")
        pred = model(img_tensor)
        pred = non_max_suppression(pred, conf_thres=0.7, iou_thres=0.45)[0]
        
        detections = []
        license_plates_detected = []
        
        # ìƒˆë¡œìš´ í”„ë ˆì„ì—ì„œ ë²ˆí˜¸íŒì´ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ë²„í¼ ì´ˆê¸°í™”
        plate_detected_in_frame = False
        
        debug_print('YOLO', f"YOLOv5 detected {len(pred) if pred is not None else 0} objects")
        
        # Process detections - platë§Œ ì²˜ë¦¬
        if pred is not None:
            for i, (*xyxy, conf, cls) in enumerate(pred):
                class_name = names[int(cls)]
                debug_print('YOLO', f"Detection {i+1}: {class_name} (confidence: {conf:.2f})")
                
                # plat í´ë˜ìŠ¤ë§Œ ì²˜ë¦¬
                if class_name.lower() == 'plat':
                    plate_detected_in_frame = True
                    debug_print('YOLO', f"âœ… License plate detected: {class_name} (confidence: {conf:.2f})")
                    print(f"License plate detected: {class_name} (confidence: {conf:.2f})")
                    
                    label = f'{class_name} {conf:.2f}'
                    xyxy = list(map(int, xyxy))
                    
                    # Scale coordinates
                    xyxy[0] = int(xyxy[0] * frame.shape[1] / 320)
                    xyxy[1] = int(xyxy[1] * frame.shape[0] / 320)
                    xyxy[2] = int(xyxy[2] * frame.shape[1] / 320)
                    xyxy[3] = int(xyxy[3] * frame.shape[0] / 320)
                    
                    debug_print('YOLO', f"Scaled coordinates: {xyxy}")
                    
                    # ë²ˆí˜¸íŒ ì˜ì—­ ì˜ë¼ë‚´ê¸°
                    x1, y1, x2, y2 = xyxy
                    
                    # ê²½ê³„ í™•ì¸ ë° ì—¬ìœ  ê³µê°„ ì¶”ê°€
                    margin = 15
                    x1 = max(0, x1 - margin)
                    y1 = max(0, y1 - margin)
                    x2 = min(frame.shape[1], x2 + margin)
                    y2 = min(frame.shape[0], y2 + margin)
                    
                    debug_print('YOLO', f"Adjusted coordinates with margin: [{x1}, {y1}, {x2}, {y2}]")
                    
                    # ìœ íš¨í•œ ì˜ì—­ì¸ì§€ í™•ì¸
                    if x2 > x1 and y2 > y1 and (x2-x1) >= 50 and (y2-y1) >= 20:
                        debug_print('YOLO', f"Valid crop area: {x2-x1}x{y2-y1}")
                        
                        try:
                            license_plate_crop = frame[y1:y2, x1:x2]
                            debug_print('OCR', f"License plate cropped: {license_plate_crop.shape}")
                            
                            # ì—°ì† í”„ë ˆì„ ê²€ì¦ì´ í¬í•¨ëœ EasyOCR ì‹¤í–‰
                            debug_print('OCR', "Starting EasyOCR with Frame Validation...")
                            print("Starting EasyOCR (Korean Priority)...")
                            ocr_text = extract_text_with_easyocr(license_plate_crop)
                            
                            if ocr_text:
                                latest_ocr_text = ocr_text
                                label = f'{class_name} {conf:.2f} [{ocr_text}]'
                                license_plates_detected.append(f"{class_name} - EasyOCR: {ocr_text}")
                                
                                # HiveMQ Cloud MQTTë¡œ OCR ê²°ê³¼ ì „ì†¡
                                safe_mqtt_publish(TOPIC_OCR, f"License Plate: {ocr_text}")
                                safe_mqtt_publish(TOPIC_LICENSE, f"Detected License: {ocr_text}")
                                debug_print('PARKING', f"ğŸ‰ License Plate Detected: {ocr_text}")
                                print(f"EasyOCR successful: {ocr_text}")
                                
                                # ì…ì¶œì°¨ ì²˜ë¦¬
                                if system_mode == "ENTRY":
                                    handle_entry(ocr_text)
                                elif system_mode == "EXIT":
                                    handle_exit(ocr_text)
                                
                                # OCR ì„±ê³µ ì‹œ ë²„í¼ ì´ˆê¸°í™” (ë‹¤ìŒ ì°¨ëŸ‰ ì¤€ë¹„)
                                clear_ocr_buffer()
                                
                            else:
                                license_plates_detected.append(label)
                                debug_print('OCR', "OCR validation pending or failed")
                                print("EasyOCR failed")
                                
                        except Exception as crop_error:
                            debug_print('YOLO', f"Cropping error: {crop_error}")
                            print(f"Cropping error: {crop_error}")
                    else:
                        debug_print('YOLO', f"Invalid crop area: {x2-x1}x{y2-y1}")
                    
                    detections.append({
                        'bbox': xyxy,
                        'label': label,
                        'class': class_name,
                        'confidence': float(conf)
                    })
        
        # ë²ˆí˜¸íŒì´ ê°ì§€ë˜ì§€ ì•Šì€ í”„ë ˆì„ì—ì„œëŠ” ë²„í¼ ì´ˆê¸°í™” (ìƒˆë¡œìš´ ì°¨ëŸ‰ ëŒ€ê¸°)
        if not plate_detected_in_frame and len(ocr_buffer) > 0:
            debug_print('YOLO', "No plate detected in frame - clearing OCR buffer")
            print("ğŸ”„ No plate detected in frame - clearing buffer for new vehicle")
            clear_ocr_buffer()
        
        # Send MQTT message if license plate detected
        if license_plates_detected:
            try:
                safe_mqtt_publish(TOPIC_STATUS, "license_plate_detected")
                safe_mqtt_publish(TOPIC_LICENSE, f"Detected: {', '.join(license_plates_detected)}")
                debug_print('MQTT', f"MQTT sent: {license_plates_detected}")
                print(f"HiveMQ Cloud MQTT sent: {license_plates_detected}")
                
                # Open gate for 5 seconds
                control_servo_motor(90)
                threading.Timer(5.0, lambda: control_servo_motor(0)).start()
                
            except Exception as e:
                debug_print('MQTT', f"MQTT transmission failed: {e}")
                print(f"HiveMQ Cloud MQTT transmission failed: {e}")
        
        debug_print('YOLO', f"Object detection completed, returning {len(detections)} detections")
        return detections
        
    except Exception as e:
        debug_print('YOLO', f"Object detection error: {e}")
        print(f"Object detection error: {e}")
        return []

def generate_frames():
    """Generate video frames for Flask streaming using webcam"""
    global latest_detections
    
    if not camera_available:
        debug_print('CAMERA', "Camera not available, generating dummy frames")
        while True:
            dummy_frame = np.zeros((480, 640, 3), dtype=np.uint8)
            cv2.putText(dummy_frame, "Webcam Not Available", (150, 240), 
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
            ret, buffer = cv2.imencode('.jpg', dummy_frame)
            if ret:
                frame_bytes = buffer.tobytes()
                yield (b'--frame\r\n'
                       b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
            sleep(0.1)
    
    debug_print('CAMERA', "Starting webcam frame generation")
    print("Webcam + EasyOCR + Frame Validation + HiveMQ Cloud video stream started")
    
    frame_count = 0
    while True:
        try:
            frame_count += 1
            if frame_count % 30 == 0:  # 30í”„ë ˆì„ë§ˆë‹¤ ë¡œê·¸
                debug_print('CAMERA', f"Capturing frame {frame_count}")
            
            # ì›¹ìº ì—ì„œ í”„ë ˆì„ ìº¡ì²˜
            ret, frame = cap.read()
            if not ret:
                debug_print('CAMERA', "Failed to capture frame from webcam")
                continue
            
            if frame_count % 30 == 0:
                debug_print('CAMERA', f"Frame captured: {frame.shape}")
            
            detections = detect_objects(frame)
            
            with detection_lock:
                latest_detections = detections
            
            # Draw bounding boxes
            for detection in detections:
                bbox = detection['bbox']
                label = detection['label']
                
                cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)
                cv2.putText(frame, label, (bbox[0], bbox[1] - 10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
            # Draw information on frame
            current_distance_display = measure_distance()
            cv2.putText(frame, f"Mode: {system_mode}", (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, f"Distance: {current_distance_display:.1f}cm (Threshold: {DISTANCE_THRESHOLD}cm)", (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, f"Status: {parking_status}", (10, 90), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(frame, f"Servo: {servo_position}Â°", (10, 120), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # OCR ê²°ê³¼ í‘œì‹œ
            if latest_ocr_text:
                cv2.putText(frame, f"Validated OCR: {latest_ocr_text}", (10, 150), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2)
            
            # OCR ë²„í¼ ìƒíƒœ í‘œì‹œ
            buffer_status = f"OCR Buffer: {len(ocr_buffer)}/5"
            cv2.putText(frame, buffer_status, (10, 180), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            
            cv2.putText(frame, f"Parked: {len(parking_data)}", (10, 210), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            
            # HiveMQ Cloud ì—°ê²° ìƒíƒœ í‘œì‹œ
            mqtt_status = "HiveMQ Connected" if mqtt_client.is_connected() else "HiveMQ Disconnected"
            cv2.putText(frame, mqtt_status, (10, 390), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0) if mqtt_client.is_connected() else (0, 0, 255), 2)
            
            # EasyOCR + Frame Validation í‘œì‹œ
            ocr_status = "EasyOCR+FrameVal (KO+EN)" if korean_support else "EasyOCR+FrameVal (EN)"
            cv2.putText(frame, ocr_status, (10, 420), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)
            
            # ì›¹ìº  í‘œì‹œ
            cv2.putText(frame, "USB Webcam", (10, 450), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            ret, buffer = cv2.imencode('.jpg', frame)
            if not ret:
                debug_print('CAMERA', "Frame encoding failed")
                continue
                
            frame_bytes = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
                   
        except Exception as e:
            debug_print('CAMERA', f"Frame generation error: {e}")
            sleep(0.1)

@app.route('/')
def index():
    """Main page with video feed"""
    korean_status = "í•œêµ­ì–´ + ì˜ì–´" if korean_support else "ì˜ì–´ë§Œ"
    mqtt_status = "ì—°ê²°ë¨" if mqtt_client.is_connected() else "ì—°ê²° ì•ˆë¨"
    
    html_template = f'''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Smart Parking System - Webcam Debug Mode</title>
        <style>
            body {{ font-family: Arial, sans-serif; text-align: center; background-color: #f5f5f5; }}
            .container {{ max-width: 1000px; margin: 0 auto; padding: 20px; background-color: white; border-radius: 10px; }}
            .video-container {{ margin: 20px 0; border: 2px solid #ddd; border-radius: 8px; overflow: hidden; }}
            .status-grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin: 20px 0; }}
            .status-box {{ padding: 15px; background-color: #e8f5e8; border-radius: 8px; border-left: 4px solid #4CAF50; }}
            .controls {{ margin: 20px 0; }}
            .btn {{ padding: 10px 20px; margin: 5px; background-color: #4CAF50; color: white; border: none; border-radius: 5px; cursor: pointer; }}
            .debug-mode {{ margin: 20px 0; padding: 15px; background-color: #fff3cd; border-radius: 8px; }}
            .hivemq-mode {{ background-color: #e8f5e9; border: 1px solid #c8e6c9; color: #2e7d32; }}
        </style>
    </head>
    <body>
        <div class="container">
            <h1>ìŠ¤ë§ˆíŠ¸ ì£¼ì°¨ ê´€ë¦¬ ì‹œìŠ¤í…œ (ì›¹ìº  + ë””ë²„ê¹… ëª¨ë“œ)</h1>
            
            <div class="debug-mode hivemq-mode">
                <h4>ì›¹ìº  + EasyOCR + ì—°ì† í”„ë ˆì„ ê²€ì¦ + HiveMQ Cloud</h4>
                <p>ì¹´ë©”ë¼: USB ì›¹ìº  | ê±°ë¦¬ ì„ê³„ê°’: {DISTANCE_THRESHOLD}cm | OCR: EasyOCR ({korean_status})</p>
                <p>ê²€ì¦ ì‹œìŠ¤í…œ: ì—°ì† 5í”„ë ˆì„ ë¶„ì„ (ì‹ ë¢°ë„ ì„ê³„ê°’: 80%)</p>
                <p>MQTT ë¸Œë¡œì»¤: HiveMQ Cloud ({mqtt_status})</p>
                <p>ëª¨ë“  ì²˜ë¦¬ ê³¼ì •ì´ í„°ë¯¸ë„ì— ìƒì„¸íˆ ì¶œë ¥ë©ë‹ˆë‹¤</p>
                <button class="btn" onclick="setMode('ENTRY')">ì…ì°¨ ëª¨ë“œ</button>
                <button class="btn" onclick="setMode('EXIT')">ì¶œì°¨ ëª¨ë“œ</button>
                <p>í˜„ì¬ ëª¨ë“œ: <span id="current-mode">{system_mode}</span></p>
            </div>
            
            <div class="video-container">
                <img src="{{{{ url_for('video_feed') }}}}" width="640" height="480" alt="Webcam Feed">
            </div>
            
            <div class="status-grid">
                <div class="status-box">
                    <h4>ìµœê·¼ ê²€ì¦ëœ ë²ˆí˜¸íŒ</h4>
                    <p id="latest-plate">ëŒ€ê¸° ì¤‘...</p>
                </div>
                <div class="status-box">
                    <h4>í˜„ì¬ ì£¼ì°¨ ì°¨ëŸ‰</h4>
                    <p id="parked-count">0ëŒ€</p>
                </div>
                <div class="status-box">
                    <h4>ê±°ë¦¬ ì„¼ì„œ</h4>
                    <p id="distance">ì¸¡ì • ì¤‘...</p>
                </div>
                <div class="status-box">
                    <h4>HiveMQ Cloud MQTT</h4>
                    <p id="mqtt-status">{mqtt_status}</p>
                </div>
            </div>
            
            <div class="controls">
                <h3>ìˆ˜ë™ ì œì–´</h3>
                <button class="btn" onclick="controlServo(0)">ê²Œì´íŠ¸ ë‹«ê¸°</button>
                <button class="btn" onclick="controlServo(90)">ê²Œì´íŠ¸ ì—´ê¸°</button>
                <button class="btn" onclick="clearBuffer()">OCR ë²„í¼ ì´ˆê¸°í™”</button>
            </div>
        </div>
        
        <script>
            function setMode(mode) {{
                fetch('/set_mode/' + mode)
                    .then(response => response.json())
                    .then(data => {{
                        document.getElementById('current-mode').textContent = mode;
                        alert('ëª¨ë“œ ë³€ê²½: ' + mode);
                    }});
            }}
            
            function controlServo(angle) {{
                fetch('/control_servo/' + angle)
                    .then(response => response.json())
                    .then(data => {{
                        alert('ì„œë³´ ëª¨í„°: ' + data.message);
                    }});
            }}
            
            function clearBuffer() {{
                fetch('/clear_ocr_buffer')
                    .then(response => response.json())
                    .then(data => {{
                        alert('OCR ë²„í¼ ì´ˆê¸°í™”: ' + data.message);
                    }});
            }}
            
            setInterval(function() {{
                fetch('/status')
                    .then(response => response.json())
                    .then(data => {{
                        document.getElementById('latest-plate').textContent = data.latest_plate || 'ëŒ€ê¸° ì¤‘...';
                        document.getElementById('parked-count').textContent = data.parked_count + 'ëŒ€';
                        document.getElementById('distance').textContent = data.distance + 'cm';
                        document.getElementById('mqtt-status').textContent = data.mqtt_connected ? 'ì—°ê²°ë¨' : 'ì—°ê²° ì•ˆë¨';
                    }});
            }}, 2000);
        </script>
    </body>
    </html>
    '''
    return render_template_string(html_template)

@app.route('/video_feed')
def video_feed():
    """Video streaming route"""
    return Response(generate_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/status')
def status():
    """API endpoint for current system status"""
    with detection_lock:
        return {
            'latest_plate': latest_ocr_text,
            'parked_count': len(parking_data),
            'distance': f"{measure_distance():.1f}",
            'mqtt_connected': mqtt_client.is_connected(),
            'system_mode': system_mode,
            'ocr_buffer_size': len(ocr_buffer),
            'parking_status': parking_status,
            'servo_angle': servo_position
        }

@app.route('/set_mode/<mode>')
def set_mode(mode):
    global system_mode
    if mode in ['ENTRY', 'EXIT']:
        system_mode = mode
        debug_print('SYSTEM', f"System mode changed to: {mode}")
        print(f"System mode changed to: {mode}")
        return {'status': 'success', 'mode': mode}
    else:
        return {'status': 'error', 'message': 'Invalid mode'}

@app.route('/control_servo/<int:angle>')
def manual_servo_control(angle):
    """Manual servo control endpoint"""
    if 0 <= angle <= 180:
        control_servo_motor(angle)
        return {'status': 'success', 'message': f'Servo moved to {angle} degrees'}
    else:
        return {'status': 'error', 'message': 'Angle must be between 0 and 180'}

@app.route('/clear_ocr_buffer')
def clear_ocr_buffer_endpoint():
    """OCR ë²„í¼ ìˆ˜ë™ ì´ˆê¸°í™” ì—”ë“œí¬ì¸íŠ¸"""
    clear_ocr_buffer()
    return {'status': 'success', 'message': 'OCR buffer cleared successfully'}

if __name__ == '__main__':
    try:
        debug_print('SYSTEM', "=== SMART PARKING SYSTEM STARTUP ===")
        print("ìŠ¤ë§ˆíŠ¸ ì£¼ì°¨ ì‹œìŠ¤í…œ ì‹œì‘ (ì›¹ìº  + ë””ë²„ê¹… ëª¨ë“œ)!")
        print("- USB ì›¹ìº  ì—°ë™")
        print("- ì‹¤ì œ GPIO í•˜ë“œì›¨ì–´ ì—°ë™")
        print("- ì…ì¶œì°¨ ê´€ë¦¬ ë° ìš”ê¸ˆ ê³„ì‚°")
        print("- HiveMQ Cloud MQTT í†µì‹ ")
        print(f"- {DISTANCE_THRESHOLD}cm ì´ë‚´ ì ‘ê·¼ ì‹œ ë²ˆí˜¸íŒ ì¸ì‹ í™œì„±í™”")
        print(f"- í˜„ì¬ ëª¨ë“œ: {system_mode}")
        print("- ìƒì„¸ ë””ë²„ê¹… ëª¨ë“œ í™œì„±í™”")
        print("- ì—°ì† í”„ë ˆì„ ê²€ì¦ ì‹œìŠ¤í…œ")
        print("ì›¹ ì¸í„°í˜ì´ìŠ¤: http://localhost:5000")
        debug_print('SYSTEM', "All systems initialized successfully")
        
        # ì´ˆìŒíŒŒì„¼ì„œ ëª¨ë‹ˆí„°ë§ ìŠ¤ë ˆë“œ ì‹œì‘
        sensor_thread = threading.Thread(target=read_ultrasonic_sensor, daemon=True)
        sensor_thread.start()
        debug_print('SYSTEM', "Ultrasonic sensor thread started")
        
        app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)
        
    except KeyboardInterrupt:
        debug_print('SYSTEM', "System shutdown initiated by user")
        print("ì‹œìŠ¤í…œ ì¢…ë£Œ...")
    finally:
        debug_print('SYSTEM', "Cleaning up resources...")
        if camera_available and cap:
            cap.release()
            debug_print('CAMERA', "Webcam released")
        mqtt_client.loop_stop()
        mqtt_client.disconnect()
        debug_print('MQTT', "MQTT client disconnected")
        GPIO.cleanup()
        debug_print('SYSTEM', "GPIO cleanup completed")
        print("ì •ë¦¬ ì™„ë£Œ")
